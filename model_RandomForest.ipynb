{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#import libraries for data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import libraries for plotting data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#import random forest library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df, test_df = pd.read_csv('data/train_fil_3.csv',index_col=0),pd.read_csv('data/validation_fil_3.csv',index_col=0),pd.read_csv('data/test_fil_3.csv',index_col=0)\n",
    "for df in [train_df,validation_df,test_df]:\n",
    "    df.columns = [int(col) for col in df.columns]\n",
    "    df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#function to calculate MAPE for all observations where y_true is not 0\n",
    "def mape(y_true, y_predict):\n",
    "    '''Returns mean percentage error for all predictions where y_true is not 0. Where y_true is 0, the percentage error is 0 as well '''\n",
    "    return np.mean([np.absolute(y_true[idx] - y_predict[idx])/y_true[idx] * 100 if y_true[idx] != 0 else 0 for idx,_ in enumerate(y_true) ])\n",
    "\n",
    "def median_pe(y_true, y_predict):\n",
    "    '''Returns mean percentage error for all predictions where y_true is not 0. Where y_true is 0, the percentage error is 0 as well '''\n",
    "    return np.median([np.absolute(y_true[idx] - y_predict[idx])/y_true[idx] * 100 if y_true[idx] != 0 else 0 for idx,_ in enumerate(y_true) ])\n",
    "\n",
    "def residuals(y_true,y_predict):\n",
    "    '''Returns list with residuals for all observations where y_true not 0. Where y_true is 0, the residuals are 0 as well '''\n",
    "    return [y_true[idx] - y_predict[idx] if y_true[idx] != 0 else 0 for idx,_ in enumerate(y_true) ]\n",
    "\n",
    "def pct_residuals(y_true,y_predict):\n",
    "    '''Returns list with percentage errors for all observations where y_true not 0. Where y_true is 0, the percentage error is 0 as well'''\n",
    "    return [(y_true[idx] - y_predict[idx])/y_true[idx] * 100 if y_true[idx] != 0 else 0 for idx,_ in enumerate(y_true) ]\n",
    "\n",
    "# Plot cumulative density function of residuals\n",
    "def residual_cdf(data):\n",
    "    '''Plots cdf of residual input data'''\n",
    "    # sort the data:\n",
    "    data_sorted = np.sort(data)\n",
    "\n",
    "    # calculate the proportional values of samples\n",
    "    p = 1. * np.arange(len(data)) / (len(data) - 1)\n",
    "\n",
    "    # plot the sorted data:\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "\n",
    "\n",
    "    ax1 = fig.add_subplot(311)\n",
    "    ax1.plot(data_sorted, p)\n",
    "    ax1.set_title('Residuals Cumulative Distribution Function')\n",
    "    ax1.set_xlabel('Residuals');\n",
    "    ax1.set_ylabel('Cumulative Distribution');\n",
    "    ax1.axvline(x=np.percentile(data,5),color='r') \n",
    "    ax1.axvline(x=np.percentile(data,95),color='r')\n",
    "\n",
    "    ax2 = fig.add_subplot(312)\n",
    "    ax2.plot([idx for idx,_ in enumerate(data)],data,'bo');\n",
    "    ax2.plot([idx for idx,_ in enumerate(data)],np.zeros(len(data)),'r-');\n",
    "    ax2.set_title('Residuals over time')\n",
    "    ax2.set_xlabel('Time in days');\n",
    "    ax2.set_ylabel('Residual');  \n",
    "    \n",
    "    #Here, we could also add Q-Q plot and auto correlation plot for the residual\n",
    "    \n",
    "def plot_prediction(y_true,y_predict):\n",
    "    '''Plots true and predicted values on same y-axis'''\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    ax1 = fig.add_subplot(311)\n",
    "    ax1.plot(range(len(y_true)), y_true,'bo')\n",
    "    ax1.plot(range(len(y_predict)),y_predict,'r-')\n",
    "    ax1.set_title('Complete prediction')\n",
    "    \n",
    "    ax2 = fig.add_subplot(312)\n",
    "    ax2.plot(range(len(y_true[:60])), y_true[:60],'bo')\n",
    "    ax2.plot(range(len(y_predict[:60])),y_predict[:60],'r-o')\n",
    "    ax2.set_title('Prediction first 60 days')\n",
    "    ax2.set_ylim(0,max(y_true))\n",
    "    ax3 = fig.add_subplot(313)\n",
    "    ax3.plot(range(len(y_true[-60:])), y_true[-60:],'bo')\n",
    "    ax3.plot(range(len(y_predict[-60:])),y_predict[-60:],'ro-')\n",
    "    ax3.set_title('Prediction last 60 days')\n",
    "    \n",
    "def management_summary(y_true,y_predict):\n",
    "    data = pd.DataFrame.from_dict({'y_true':y_true, 'y_predict':y_predict})\n",
    "    \n",
    "    #only regard data where y_true is not 0\n",
    "    ex_0 = data[data['y_true'] != 0]\n",
    "    \n",
    "    #calculate how ofter we under- and over-estimate the revenue\n",
    "    pct_lower = round(sum(ex_0.y_predict - ex_0.y_true < 0)/len(ex_0.y_true) * 100,1)\n",
    "    pct_higher = round(100 - pct_lower,1)\n",
    "    \n",
    "    #calculate cumulative sums of under- and over estimation\n",
    "    cumsum_lower = np.cumsum([np.abs(ex_0.y_predict[idx] - ex_0.y_true[idx]) if ex_0.y_predict[idx] < ex_0.y_true[idx] else 0 for idx,y in enumerate(ex_0.y_true) ])\n",
    "    cumsum_higher = np.cumsum([np.abs(ex_0.y_predict[idx] - ex_0.y_true[idx]) if ex_0.y_predict[idx] > ex_0.y_true[idx] else 0 for idx,y in enumerate(ex_0.y_true)])\n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    ax1.plot(range(len(ex_0.y_true)), cumsum_lower,'b-o')\n",
    "    ax1.plot(range(len(ex_0.y_true)),cumsum_higher,'r-o')\n",
    "    \n",
    "    ax1.set_title('Cumulative Sums of Under- and Over-Estimation')\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Cumulated sum of errors')\n",
    "    ax1.legend(['Under Estimation', 'Over Estimation', 'True Values'])\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'black'\n",
    "    ax2.set_ylabel('Measured Values', color = color)\n",
    "    ax2.plot(range(len(ex_0.y_true)),ex_0.y_true,'--', color=color, marker=10)\n",
    "    \n",
    "    return f'The model underestimates {pct_lower}% of the time'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add features related to time\n",
    "def df_add_timefeatures(dataframe):\n",
    "    '''Adds features related to time that are generated from datetime index of dataframe'''\n",
    "    dataframe['day_of_week'] = [x.weekday() +1 for x in dataframe.index]\n",
    "    dataframe['day_of_month'] = [x.date().day for x in dataframe.index]\n",
    "    dataframe['day_of_year'] = [x.dayofyear for x in dataframe.index]\n",
    "    dataframe['weekofyear'] = [x.weekofyear for x in dataframe.index]\n",
    "    dataframe['month'] = [x.month for x in dataframe.index]\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add lag values to dataframe\n",
    "def df_add_lagvalues(dataframe,y_column,lagvalues):\n",
    "    for lag in lagvalues:\n",
    "        #shift values \n",
    "        dataframe['lag_'+str(lag)] = dataframe[y_column].shift(periods=lag)\n",
    "        #exchange the first NAN values for true y values\n",
    "        #dataframe['lag_'+str(lag)][:lag] = dataframe[y_column][:lag]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get one value for lag of size n for step-forward prediction\n",
    "def get_lagvalue(history,lagvalue):\n",
    "    if len(history) < lagvalue:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return history[-(lagvalue):-(lagvalue-1)][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add mean value for weekday in past n weeks to dataframe\n",
    "def df_add_weekdaymean(dataframe,column,weeks):\n",
    "    \n",
    "    dataframe['weekdaymean_'+str(weeks)+'_weeks'] = [np.mean([get_lagvalue(dataframe[column][:idx],7*n) for n in range(1,weeks+1)]) for idx in range(len(dataframe))]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mean value for weekday in past n weeks for one step in step-forward prediction\n",
    "def get_weekdaymean(history,weeks):\n",
    "    return np.mean([get_lagvalue(history,7*n) for n in range(1,weeks+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_featurefun(df,column,history_df=[]):\n",
    "    if len(history_df) >0:\n",
    "        dataframe = pd.concat((history_df[[column]],df[[column]]))\n",
    "    else:\n",
    "        dataframe = df[[column]]\n",
    "    \n",
    "    dataframe.columns = ['y']\n",
    "    \n",
    "    for i in [7,14]:\n",
    "        dataframe['lag_'+str(i)] = [get_lagvalue(dataframe['y'][:idx],i) for idx in range(len(dataframe))]\n",
    "    for i in [2,4]:\n",
    "        dataframe['weekdaymean_'+str(i)+'_weeks'] = [get_weekdaymean(dataframe['y'][:idx],i) for idx in range(len(dataframe))]\n",
    "            \n",
    "    dataframe = df_add_timefeatures(dataframe)\n",
    "    \n",
    "    return dataframe[-len(df):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leo/anaconda3/envs/nf/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/Users/leo/anaconda3/envs/nf/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/Users/leo/anaconda3/envs/nf/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/Users/leo/anaconda3/envs/nf/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/Users/leo/anaconda3/envs/nf/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/Users/leo/anaconda3/envs/nf/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/Users/leo/anaconda3/envs/nf/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = apply_featurefun(train_df,6), apply_featurefun(validation_df,6,train_df), apply_featurefun(test_df,6,validation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Random Forest Parameters for Best Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
